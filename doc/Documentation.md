# Overview

The [lego](https://go-acme.github.io/lego/) library powers ACME negotiation in Traefik, and includes a collection of drivers for DNS providers enabling their use with the DNS-01 challenge. For providers lacking native drivers, it offers two generic ones that can be used to glue the support in: [exec](https://go-acme.github.io/lego/dns/exec/index.html) and [httpreq](https://go-acme.github.io/lego/dns/httpreq/index.html). This was the case with Openprovider when integrating DNS-01 with Traefik, which motivated the start of this project.

Initial testing and development were done interactively using certbot to manage certificates and perform challenges, with a Bash wrapper providing **challenge hooks**: handlers that lego/Traefik or certbot call to create TXT records that an ACME server such as Let’s Encrypt will query to validate DNS-01 challenges.

While working with the hook code it was found that:

- Certbot does not verify that the newly created TXT record has propagated through the DNS data plane before returning control to ACME, meaning any propagation checks must be performed before the hook returns.
- With lego/Traefik, an optimistic polling with backoff and timeout greenlights ACME as soon as the first positive lookup is received. In the case of Openprovider, this detection logic caused DNS-01 validations to fail in a [number of scenarios](#adaptive-propagation-detection-the-native-mode).

The main effort therefore focused on improving the guarantees of TXT record convergence in the shortest possible time. After the hooks request TXT creation, all authoritative servers are polled for **streaks** of positive replies. Success thresholds and backoff intervals are adaptive and change depending on whether DNS shows “good” or “bad” convergence.

The other missing piece was Kubernetes integration, covered in detail later in this documentation (particularly for Traefik). Upcoming development will focus on making **dns01** more broadly useful:

-  support additional DNS providers (via lego drivers or a native plugin system)
- support more ACME clients besides lego/Traefik, such as cert-manager or custom workflows
- deeper integration with the Argo ecosystem
- make the internal components usable independently (A/AAAA target creation, propagation detection, etc.)

# Components

## `dns01/common`

Like the name implies this is code that is reused from other scripts. It does things like error handling, output formatting and so on.



## `dns01/rest`

This is a minimal script to interact with REST APIs intended for scripting or CLI usage, similar to [httpie](https://httpie.io/).

### Requirements

- jq
- curl
- the `dns01/common` script

### Configuration

These entries are expected to be defined in a `conf` associative array:

| `conf[]` entry |                           Defines                            |
| :------------: | :----------------------------------------------------------: |
|     `api`      |       Base URL to where requests are sent (target API)       |
|   `auth_ep`    |     Authentication endpoint path component at target API     |
|   `auth_req`   | A string as per the target API login request format. The first and second `%s` entries are mapped to the username and password (or analogous secret token). |
|   `auth_tok`   | The JSON node in the reply where to look for the token when authentication succeeds, as per the target API. It must start with a dot ("."). |
|   `auth_var`   | The name of a variable to export with the authentication token |

 These variables are used when set in the script or environment:

|    variable     |                        Defines                         |
| :-------------: | :----------------------------------------------------: |
| `REST_USERNAME` |         The username to use for authentication         |
| `REST_PASSWORD` | The password or secret token to use for authentication |

When either variable is unset, the script prompts interactively (if running on a TTY) and pauses until the information is entered.

### Usage

Functions in `rest` can be used directly when calling the script by passing them as the first argument, so they can be seen as subcommands. Useful subcommands are `enc`, `auth` and the autogenerated `req()` wrappers: `post`, `get`, `put`, `delete`, `patch` and `postj`, `getj`, `putj`, `deletej`, `patchj`.

#### `rest enc <format> <k=v> [k=v ...]`

Encode a series of strings representing key=JSON pairs into the chosen format:

- `raw` format: outputs the raw input using `printf`
-  `uri` format: encodes the input into a query string  
- `json` format: encodes the input into JSON

When using JSON formatting, all key=value input pairs are merged into a top level dictionary that is initially set to `{}`. Each key is a member in that dictionary, and each value is type checked and formatted according to the following rules:

- key and value should be separated by an equal (`=`) character, with no spaces around it
- scalar values and dictionaries go through `jq -R @json` so any recursive formatting in dictionaries is done through this tool 
- lists are processed recursively. The auxiliary function `comma_items()` extracts top-level items inside the currently processed list before each item is individually type-checked and encoded.

Since all scalar values and dictionaries are filtered through jq and arrays recursed over, proper type checking is done for all JSON types. Typecheck errors from jq or this subcommand will fail parsing and abort any call. 

To avoid brace expansion and other shell mangling on the input it is advised to wrap the outermost dictionaries in single quotes:

```bash
./dns01/rest enc json domain='{"extension":"com", "name":"test"}' type=master records=['{"name":"www","ttl":"900","type":"A","value":"1.2.3.4"}','{"name":"ftp","ttl":"900","type":"CNAME","value":"test.com"}']
```



#### `rest auth [user] [pass]`

Attempt authentication via POST and return an authentication token.

User name and password can be passed as arguments or via `REST_USERNAME` and `REST_PASSWORD`. If the tokens aren't found in the arguments or the environment, the function will prompt for them on a console (provided a TTY is detected) and stop until they are entered.

On successful authentication, the returned authorization token will be printed on standard output, and if `conf[auth_var]` is set, exported in the variable whose name is there defined.

To use this in the current environment you can source the call:

```bash
source ./dns01/rest auth
```
Or, substitute the command:
```bash
export MY_TOKEN="$(./dns01/rest auth)"
```

 

#### `rest <post|get|put|delete|patch> [--raw] [k=v ...]`

The request wrapper subcommands merely encode the HTTP method in their name so that `req()` receives it as an implicit parameter, so they are there for purely ergonomic purposes. There is also a second set of wrappers (`postj`, `getj`, `putj`, `deletej`, `patchj`) that will pretty-print the response output by piping it through jq.

`req()` performs the HTTP request and if there are no errors, prints out the response. An authentication token is expected to be defined in the variable pointed to by `conf[auth_var]`, otherwise the function will call `auth()` in an attempt to get a token prior to sending the requests.

##### method encoding

The default encoding format for `k=v` arguments depends on the method in use:

- POST, PUT, PATCH -> JSON encoding

- GET, DELETE -> URI encoding

The `--raw` argument can be passed first to force that format, essentially disabling encoding by the `rest` script. This is useful when encoding should be handled outside of the `rest` script.



## `dns01/dns01`
A script to assist with DNS-01 ACME challenges.

**dns01** can:

- generate the certificate material from scratch using certbot. Apex, wildcard and combo domains (apex+wildcard) are supported.
- create the target A/AAAA records on target DNS APIs (currently only Openprovider supported).
- perform (robust) DNS-01 challenge detection, with the certificate material managed by clients or by certbot. This is used with lego/Traefik and also supports integration with cert-manager or other clients.

### Requirements

- dnsutils
- certbot (if using certificate generation)
- the `dns01/rest` script
- the `dns01/common` script

### Configuration

These entries are expected to be defined in a `conf` associative array:

|      `conf[]` entry      |                           Defines                            |
| :----------------------: | :----------------------------------------------------------: |
|      `rest_client`       |     The path to the `rest` script or equivalent program      |
|      `acme_staging`      |              The URL of an ACME staging server               |
|       `acme_live`        |                The URL of an ACME live server                |
|       `acme_email`       |            The email to use for ACME registration            |
|      `dns01_native`      |    Propagation detection - enable/disable native tracking    |
|     `dns01_timeout`      |            Propagation detection - global timeout            |
|     `dns01_backoff`      |         Propagation detection - initial backoff time         |
|   `dns01_backoff_min`    |         Propagation detection - backoff lower bound          |
|   `dns01_backoff_max`    |         Propagation detection - backoff higher bound         |
|      `dns01_streak`      |    Propagation detection - enable/disable streak tracking    |
| `dns01_streak_threshold` | Propagation detection - initial target streak to succeed tracking |
|  `dns01_streak_penalty`  | Propagation detection - streak threshold penalization speed  |
|    `dns01_streak_mod`    | Propagation detection - streak threshold penalization speed  |

 These variables are used when set in the script or environment:

|         Variable         |      `conf[]` entry      |                            Values                            |
| :----------------------: | :----------------------: | :----------------------------------------------------------: |
|      `DNS01_NATIVE`      |      `dns01_native`      | `true`: fully disable lego semantics<br>`false`: fully enable lego semantics (can't be overriden)<br>`fallback`: try `false` behavior first otherwise `true` behavior<br/>(`DNS_*` variables can override)<br>`<any other value>`: enable lego semantics<br/>(`DNS_*` variables can override) |
|     `DNS01_TIMEOUT`      |     `dns01_timeout`      | `<integer value>`: set `conf[]` value<br/>`<any other value>`: use `conf[]` value |
|     `DNS01_BACKOFF`      |     `dns01_backoff`      | `<integer value>`: set `conf[]` value<br/>`<any other value>`: use `conf[]` value |
|   `DNS01_BACKOFF_MIN`    |   `dns01_backoff_min`    | `<integer value>`: set `conf[]` value<br/>`<any other value>`: use `conf[]` value |
|   `DNS01_BACKOFF_MAX`    |   `dns01_backoff_max`    | `<integer value>`: set `conf[]` value<br/>`<any other value>`: use `conf[]` value |
|      `DNS01_STREAK`      |      `dns01_streak`      |                      `true` or `false`                       |
| `DNS01_STREAK_THRESHOLD` | `dns01_streak_threshold` | `<integer value>`: set `conf[]` value<br>`<any other value>`: use `conf[]` value |
|  `DNS01_STREAK_PENALTY`  |  `dns01_streak_penalty`  | `<integer value>`: set `conf[]` value<br/>`<any other value>`: use `conf[]` value |
|    `DNS01_STREAK_MOD`    |    `dns01_streak_mod`    | `<integer value>`: set `conf[]` value<br/>`<any other value>`: use `conf[]` value |

### Usage

**dns01** supports different operation modes. This will be extended in following versions to be able to use parts of what is now the Certbot mode independently.

The hook modes deal only with propagation detection of the DNS-01 challenge record. They are called by Certbot or Traefik/lego when they are used to create certificates and conduct the DNS-01 challenge. Again, in following versions this is where support for other certificate/DNS-01 brokers such as cert-manager will be added.

Custom brokers can use the hook calls as desired, by following their usage documented below.

#### Certbot mode

`dns01 [--create] [--addr <address> ...] [--combo] [--live] <domain>`

In this mode Certbot creates the TLS certificate and handles DNS-01.

By default the certificate will be issued for the specified domain, which can be an apex or a wildcard domain. If `--combo` is specified, a certificate will be issued for both the apex and wildcard domain, deriving the second entry from the specified domain.

The Certbot mode defaults to using the ACME server defined in `conf[acme_staging]`. To use the server defined in `conf[acme_live]`, use the `--live` switch.

This mode supports creating the actual A/AAAA target records in DNS before starting the DNS-01 challenge when the `--create` switch is present. At least one address must be also specified for the record with the `--addr` switch (this can be used many times for multiple address targets). Both IPv4 and IPv6 addresses are supported, and both types can be passed in the same call.

> **Note**
> `--create` is ignored if the specified domain is a wildcard domain

#### Certbot hook mode

`dns01 certbot_hook <add|del>`

After Certbot starts the DNS-01 challenge, it will call **dns01** back to create (`add`) or delete (`del`) the TXT challenge record. After adding the record, the script will attempt propagation detection.

The hook expects the target domain and DNS-01 challenge token to be defined in the `CERTBOT_DOMAIN` and `CERTBOT_VALIDATION` environment variables, as per Certbot semantics.

#### Traefik/lego hook mode

`dns01 certbot_hook <present|cleanup> <domain> <token>`

After Traefik/lego start the DNS-01 challenge, it will call **dns01** back to create (`present`) or delete (`cleanup`) the TXT challenge record. After adding the record, the script will attempt propagation detection.

The hook expects the target domain and DNS-01 challenge token to be passed on the command line, as per lego `exec` specification in the arguments.

> **Note**
> lego exec "raw" mode is not supported at this time

### Adaptive propagation detection (the "native" mode)

A DNS provider data plane can return flaky results (e.g. from anycast clusters with unpredictable zone updates), so **dns01**'s propagation detection will not trust a single test, *even when all authoritative servers did answer correctly*.

If we succeed the challenge propagation only to have Let's Encrypt fail in the face of a flapped NXDOMAIN or stale record, we're in no better position as having had no propagation checks at all.

Thus, `wait_propagation()` actively seeks to detect whether we're in presence of one of these worst cases, and works its way with inconsistent data planes to minimize the chance of false positives. This is done by tracking the data plane responses while it converges.

How does this work exactly? We define the following:

- **timeout**

  How many seconds will pass until we give up and totally fail propagation detection

- **successful probe**

  **All** authoritative servers have returned the TXT challenge record. This may happen in a single pass or after multiple passes.

- **failed probe**

  At least **one** authoritative server has not returned the TXT challenge record.

- **success streak**

  Consecutive successful probes. This is a measure of confidence in the data plane having achieved convergence. Any failed probe will end the streak.

- **streak length threshold**

  How long a series of successful probes a success streak should cover, in order to trust the streak.

- **length threshold penalization**

  When a probe fails, the streak length threshold is raised, which means that *future success streaks must be stronger* in order to trust them. When the data plane appears to respond better, confidence will tend again to build faster.

  How aggressively (or how often) we penalize the threshold is controlled by `conf[dns01_streak_mod]`. Lower values will penalize more often.

- **streak time threshold**

  How many seconds a success streak should extend to declare full confidence in the streak. Using a time threshold allows to correct for overly short or long streak length thresholds, improving confidence and response time.

  The streak time threshold is not configurable yet, but will be in a future version.

- **backoff time**

  How long to wait between probes. This helps to avoid two things: throttling at the DNS provider (by probing too fast), and bad propagation detection times (by probing too slow).

  The back-off time will move in a configurable window depending on whether the probes succeed (value is reduced), or fail (value is increased).
  
  Setting the low, high, and initial backoff times to the same value will disable backoff scaling and force a constant interval. See also [lego behavior](#traefiklego-behaviors).  

The final outcome is decided by whichever comes first:

|                      Condition                      | Result  |
| :-------------------------------------------------: | :-----: |
| Streak tracking is disabled, and any probe succeeds | Success |
|    The streak time and length thresholds are met    | Success |
|    The streak time threshold is exceeded by 200%    | Success |
|               The timeout is reached                | Failure |



#### Performance and reliability

`dns01` can work with DNS services showing delayed or inconsistent propagation, but it has no chance to affect in any way the time it takes for those services to converge.

With Openprovider, propagation delays and record flapping were observed when multiple TXT records for the same `_acme-challenge` name are created rapidly, which can happen from things like:

- Using the `--combo` option (multiple names in one certificate request)
- Multiple concurrent or closely timed challenges for the same domain from different certificate requests

The propagation detection logic attempts to maximize success rate and minimize resolution time under poor conditions, but this has the potential to raise validation times significantly (10-20 minutes per record in extreme cases).

Possible mitigation routes are:

- Avoid `--combo` for automation
- Avoid concurrent or near-concurrent certificate requests for the same domain  
- Use `conf[dns01_timeout]` and related controls to set acceptable timeout, backoff and streak behavior for your environment

#### Traefik/lego behaviors

In the Traefik hook flow, the lego [`exec`](https://go-acme.github.io/lego/dns/exec/) provider sets two environment variables with default values:

- `EXEC_POLLING_INTERVAL` - Time between DNS propagation check in seconds (Default: 3)
- `EXEC_PROPAGATION_TIMEOUT` - Maximum waiting time for DNS propagation in seconds (Default: 60)

These variables conform to the lego timeout/poll/first positive propagation detection. They map to **dns01** native configuration and behavior like follows:

|   Traefik/lego variable    |                        `conf[]` entry                        |                            Notes                             |
| :------------------------: | :----------------------------------------------------------: | :----------------------------------------------------------: |
| `EXEC_PROPAGATION_TIMEOUT` |                       `dns01_timeout`                        |                         1:1 mapping                          |
|  `EXEC_POLLING_INTERVAL`   | `dns01_backoff`<br>`dns01_backoff_min`<br>`dns01_backoff_max` | The `backoff` variable in `wait_propagation` moves in the range, or can be set to a fixed interval |
|             -              | `dns01_streak_threshold`<br>`dns01_streak_penalty`<br>`dns01_streak_mod`<br>`dns01_streak` | Dynamic time/length based streak tracking have no equivalent in Traefik. To follow its semantics `dns01_streak` must be set to `false`. |

**When running the Traefik hook**, `dns01` propagation detection semantics are controlled at a high level with the `DNS01_NATIVE` environment variable (default unset):

|          value          |                            result                            |
| :---------------------: | :----------------------------------------------------------: |
|         `true`          |            Use dns01 native propagation detection            |
|         `false`         |          Use lego compatible propagation detection           |
|       `fallback`        |             Try lego first, fall back on native              |
| unset / any other value | Like `false`, but `DNS01_STREAK`, `DNS01_TIMEOUT`, `DNS01_BACKOFF_MIN` and `DNS01_BACKOFF_MAX` can override behavior (see [Configuration)](#configuration). |

When lego compatible semantics are used:

- `dns01_timeout` is set to `EXEC_PROPAGATION_TIMEOUT`
- `dns01_backoff`, `dns01_backoff_min` and `dns01_backoff_max` are all set to `EXEC_POLLING_INTERVAL`
- `dns01_streak` is set to `false`, disabling streak tracking

> **Note**
> When using lego detection but enabling backoff scaling, the scaling can only be **positive**, ie. increased on failed probes, as the first successful probe totally succeeds detection.



## `spool.sh`

A generic, single-queue micro spool written for POSIX. It consists of one long-running function working as the spooler daemon and one synchronous function that writes requests to and read responses back from the spool directory.

The spooler is started targeting one program, and any requests along with their arguments are sent via the synchronous calls. When the spooler finds a new request, it reads all the arguments for its target and calls it in background. The background call waits for the target to return, and writes the exit status in a response file. 

This is the mechanism used to set up **dns01** as a Traefik `exec` plugin as described in its own section, but can wrap any target command.

### requirements

None

### configuration

These variables are used when set in the script or environment:

|    variable     |                       Defines                       |                           Default                            |
| :-------------: | :-------------------------------------------------: | :----------------------------------------------------------: |
|   `SPOOL_JOB`   |                 The target command                  |                         `/bin/false`                         |
|   `SPOOL_DIR`   | The directory to use for the request/response files | A `/spool` subdirectory relative to the path of the script instance |
| `SPOOL_TIMEOUT` |   Seconds before giving up and returning an error   |                            `1500`                            |

### usage

`spool.sh help`

Shows online help

`spool.sh daemon`

Starts the spool daemon

`spool.sh [args ...]`

Sends a request to call the target program, forwarding any arguments in the call. Returns 1 if `SPOOL_TIMEOUT` is reached, or the exit code of the target program. This is a standard synchronous, blocking command.



## `entrypoint`

This is a standard frontend script supporting the different container operation modes, used as the Dockerfile ENTRYPOINT.

### requirements

- Bash 4
- The `dns01` and `spool.sh` scripts

### configuration and usage

The variable `DNS01_PATH` should point to this repository. Refer to [Docker image](#docker-image) below for full details.

# Set up and deployment

## Standalone use

Add the `dns01` subdirectory in this repo to your `PATH` (advised) or call the scripts there directly. The code will determine its filesystem location and find its own components when necessary. The `rest` and `spool.sh` scripts can be used independently.

All the details on setting up and using the different scripts are found in their own [sections](#Components).

## Docker image

The repository includes a Dockerfile that builds a self-contained container image with all the files in this repository and the necessary dependencies.

### Building the image

From the repository root:

```
docker build -t ghcr.io/onestein/dns01:latest .
```

(Adjust the tag to whatever registry/namespace you use.)

### Running locally

Idle mode:

```
docker run --rm -e DNS-01_MODE=idle ghcr.io/onestein/dns01:latest
```

Spool worker:

```
docker run --rm \
  -e DNS-01_MODE=spool \
  -e SPOOL_DIR=/var/spool/dns01 \
  -e SPOOL_JOB=/opt/dns01/dns01 \
  -v "$(pwd)/spool:/var/spool/dns01" \
  ghcr.io/onestein/dns01:latest
```

In this example:

- The host directory `./spool` is mounted into the container as `/var/spool/dns01`.
- A producer process (another container or a host script) can write jobs into that directory using the same spool protocol as `spool.sh` (request/response files with base64-encoded argv).
- The dns01 container processes those jobs using the `dns01` script as `SPOOL_JOB`.

### Entrypoint and modes

The Docker image ships with an opinionated `entrypoint` script that selects the runtime behavior based on the `DNS01_MODE` environment variable.

At the moment only `idle` and `spool` modes are implemented. Other modes are reserved for future work and will exit with a non-zero status.

#### idle mode (default)

This is a test mode that just loops and does nothing except logging a message

#### spool mode

This mode runs a `spool.sh` worker targeting `dns01`:

- `spool.sh` is run in daemon mode, watching a spool directory
- each spooled request is expected to contain one command line to be passed to a `dns01` execution

The `DNS01_SPOOL` variable should point to a directory that will be used for the spool. If unset, the value of `SPOOL_DIR` is used - unless it's also unset, in which case `DNS01_PATH `will be used as the fallback default.

The entry point attempts to create the spool directory that `spool.sh` will use, depending on whether `DNS01_SPOOL` and  `SPOOL_DIR` are defined.

## Traefik plugin

The instructions here are intended for Traefik deployments with the [official Helm chart](https://github.com/traefik/traefik-helm-chart). If your setup differs you will have to adjust accordingly.

At present the Traefik interface is deployed as an `exec` plugin. There are two main ways to do this:

- Use a Traefik image where **dns01** is included, and provide a writable location for the spool directory.

- Use the original Traefik image, spawn the **dns01** image in spool mode as a sidecar, and dispatch the requests by calling the synchronous spool interface on the Traefik container using a shared volume. 

  This is the strategy documented here.

We avoid defining `SPOOL_DIR` (the actual spool directory), and rely on the [defaults in `spool.sh`](#configuration-2) targeting a spool subdirectory under its own exec path. For this to work, both the Traefik `EXEC_PATH` and the entry point call *must use the same path*.

### 1) Set up the shared volume and spool directory

Define the volume and mount on the Traefik container:

```yaml
additionalVolumes:
 - name: acme-scripts
   mountPath: /acme-scripts
   readOnly: false 
   
additionalVolumeMounts:
  - name: acme-scripts
    mountPath: /acme-scripts
    readOnly: false   
```

Although the entry point attempts to create the spool directory if it doesn't exist, the bulletproof way to prevent authorization issues with Traefik is to do this on a root init container:

```yaml
initContainers:
  # The "volume-permissions" init container is required if you run into permission issues.
  # Related issue: https://github.com/traefik/traefik-helm-chart/issues/396
  - name: volume-permissions
    image: busybox:latest
    command:
      - sh
      - -c
      - |
        echo "Setting up /acme-scripts..."
        mkdir -p /acme-scripts/spool
        chown -R <traefik uid>:<traefik gid> /acme-scripts
        chmod -R 700 /acme-scripts
    securityContext:
      runAsNonRoot: false
      runAsUser: 0
      runAsGroup: 0
    volumeMounts:
      - name: acme-scripts
        mountPath: /acme-scripts
```

### 2) Set up **dns01** as a sidecar in spooled mode 

```yaml
additionalContainers:
  - name: onestein-dns01
    image: ghcr.io/onesteinbv/dns01:latest
    imagePullPolicy: Always
    volumeMounts:
      - name: acme-scripts
        mountPath: /acme-scripts
        readOnly: false
    env:
    - name: REST_USERNAME
      valueFrom:
        secretKeyRef:
          name: traefik
          key: openprovider_username
    - name: REST_PASSWORD
      valueFrom:
        secretKeyRef:
          name: traefik
          key: openprovider_password
    - name: DNS-01_MODE
      value: spool
    - name: DNS-01_SPOOL
      value: /acme-scripts
    - name: DNS-01_NATIVE
      value: "true" 
```

### 3) Set up the spool interface as an `exec` plugin

```yaml
env:
- name: EXEC_PATH
  value: /acme-scripts/spool.sh
    
certificatesResolvers:
  dns01:
    acme:
      email: acme-challenge@onestein.nl
      storage: /data/acme.json
      tlsChallenge: false
      httpChallenge: false
      dnsChallenge:
        provider: exec
        disablePropagationCheck: true
```

> **Notes**
>
> -  `/data` is a persistent volume for the certificate store. Please refer to the Traefik [documentation on ACME](https://doc.traefik.io/traefik/reference/install-configuration/tls/certificate-resolvers/acme/) for more information.
> - When using the **dns01** native propagation checks (`DNS01_NATIVE=true`), disable the lego checks on the certificate resolver with `disablePropagationCheck: true`. See [Usage](#usage-1) and [Notes](#adaptive-propagation-detection-the-native-mode) for details.
